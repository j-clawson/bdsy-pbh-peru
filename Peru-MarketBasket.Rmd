---
title: "Peru Market Basket Analysis"
author: "James Clawson"
date: "2025-07-09"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Market Basket Analysis --> load the required packages

```{r}
#| message: FALSE
#| warning: FALSE

suppressPackageStartupMessages({
  library(tidyverse)
  library(knitr)
  library(ggplot2)
  library(lubridate)
  library(arules)
  library(arulesViz)
  library(plyr)
  library(RColorBrewer)
  library(plotly)
})

```


## Load the gps data

NOTE: Location of csv file may be different, adjust accordingly

```{r}
peru_gps <- read.csv('data\\peru_gps.csv')
```

Note that there are redundant columns (such as Continent and Country). Let's remove these and store the result in gpsClean.
```{r}
gpsClean <- peru_gps %>% dplyr::select(-Continent, -Country, -Sample, -Sample_name, -Public_name, -Lane_id, -Year, -ERS)
```

Market Basket Analysis requires categorical (discrete) variables. So what about continuous variables such as Penicillin levels? We must categorize them to include the data in our analysis.
```{r}
# Categorize Penicillin Levels

penicillin_raw <- as.character(gpsClean$Penicillin)
penicillin <- suppressWarnings(as.numeric(penicillin_raw))

penicillin_binned <- cut(penicillin,
                      breaks = c(-Inf, 0.06, 0.25, 1, Inf),
                      labels = c("Very Low", "Low", "Meduium", "High"))

penicillin_binned <- as.character(penicillin_binned)
penicillin_binned[penicillin_raw == 'S'] <- 'Susceptible'
penicillin_binned[penicillin_raw == 'NS'] <- 'Non-Susceptible'

gpsClean$newPenicillin <- penicillin_binned
gpsClean <- gpsClean %>% select(-Penicillin)
```


Finally, we can transform our data into a list of transactions
```{r}
tr <- as(gpsClean, "transactions")
```

```{r}
print("Description of the transactions")
summary(tr)
```

Which items occur most frequently? There are two approaches.

1) Absolute Count
```{r}
itemFrequencyPlot(tr, topN=25,type="absolute",col=brewer.pal(8, "Pastel2"),main = "gpsClean transaction count")
```

2) Relative Frequency
```{r}
itemFrequencyPlot(tr, topN=25,type="relative",col=brewer.pal(8, "Pastel2"),main = "gpsClean transaction count")
```


## Create rules

Finally, let's use the Apriori algorithm from the arules package to look for itemsets

Since each transaction consists of 30 or 31 items (as seen above from the summary function), let's set the maximum considered length for each rule to 5. Furthermore, let's raise our support threshold to 0.05 to limit the number of computations and our confidence threshold to 0.9.

```{r}
rules <- apriori(tr, parameter = list(supp = 0.015, confidence = 0.8, maxlen = 4), control = list(verbose = TRUE))
rules <- sort(rules, by = c("confidence"), decreasing = TRUE)
summary(rules)
```

Now let's inspect some of our rules!
```{r}
inspect(rules[1:10])
```


```{r}
test <- read.csv("data\\peru_gene_presence_absence.csv")
```